{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "import IPython\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from src.data import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "path_workdir: Path = Path(pyrootutils.find_root(search_from=os.curdir, indicator=\".project-root\"))\n",
    "os.chdir(Path(path_workdir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis -- Subtask A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.create_split_subtask_a import create_subtask_a_df\n",
    "df = create_subtask_a_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = df[\"label\"].value_counts().T.plot.bar()\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.xticks([0,1], [\"Sentence doesn't makes sense\", 'Sentence makes sense'], rotation=0)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of labels in subtask A')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **We can perform random label split without worrying about split balance and dataset label distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.defaults import PATH_TEST_A, PATH_TRAIN_A\n",
    "\n",
    "df_train, df_test = pd.read_csv(PATH_TRAIN_A), pd.read_csv(PATH_TEST_A)\n",
    "ax = plt.bar([\"Train split\", \"Test split\"], [df_train[\"label\"].count(), df_test[\"label\"].count()])\n",
    "plt.bar_label(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "all_bins = np.arange(1, max(df[\"sentence_length\"]) + 2, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.set_title('Distribution of number of words in a sentence per split')\n",
    "ax.set_xticks(all_bins[:-1])\n",
    "a_heights, a_bins = np.histogram(df_train['sentence_length'], bins=all_bins, density=True)\n",
    "b_heights, b_bins = np.histogram(df_test['sentence_length'], bins=a_bins, density=True)\n",
    "\n",
    "a_heights = a_heights * 100\n",
    "b_heights = b_heights * 100\n",
    "\n",
    "bin_width = (a_bins[1] - a_bins[0])/3\n",
    "half_width = bin_width / 2\n",
    "\n",
    "ax.bar(a_bins[:-1] - half_width, a_heights, width=bin_width, label='Train split')\n",
    "ax.bar(b_bins[:-1] + half_width, b_heights, width=bin_width, label='Test split')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "ax.set_xlabel('Number of words in a sentence')\n",
    "ax.set_ylabel('Percentage of sentences')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèñÔ∏è Playground area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "# https://huggingface.co/docs/datasets/main/index\n",
    "dataset = Dataset.from_pandas(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaV2TokenizerFast\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
